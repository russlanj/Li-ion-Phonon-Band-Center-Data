{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e691d2db",
   "metadata": {},
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89d0ae82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from lazypredict.Supervised import LazyRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import math\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea06134",
   "metadata": {},
   "source": [
    "# Loading the data and applying feature filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1683c6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data\n",
    "df = pd.read_csv(\"2_Full Dataset (Features).csv\")\n",
    "\n",
    "#designating X and Y\n",
    "mp_id = df['mp_id']\n",
    "df1 = df.drop(['material', 'mp_id','phonon_band_center','counter'], axis=1)\n",
    "Y = df['phonon_band_center']\n",
    "\n",
    "#Feature filtering (variance threshold)\n",
    "vt = VarianceThreshold(threshold=0)\n",
    "vt.fit(df1)\n",
    "vt.get_support()\n",
    "concol = [column for column in df1.columns\n",
    "           if column not in df1.columns[vt.get_support()]]\n",
    "df2 = df1.drop(concol, axis=1)\n",
    "df2 = df2.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb08fcf",
   "metadata": {},
   "source": [
    "Pearson and Spearman correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1e9b5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Spearman and Pearson correlations\n",
    "\n",
    "def correlation(dataset, threshold):\n",
    "    col_corr = set()  # Set of all the names of correlated columns\n",
    "    corr_matrix = dataset.corr(method='spearman')\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n",
    "                colname = corr_matrix.columns[j]  # getting the name of column\n",
    "                col_corr.add(colname)\n",
    "    af_corr = dataset.drop(col_corr,axis=1)\n",
    "    return af_corr\n",
    "\n",
    "def correlation2(dataset, threshold):\n",
    "    col_corr = set()  # Set of all the names of correlated columns\n",
    "    corr_matrix = dataset.corr(method='pearson')\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n",
    "                colname = corr_matrix.columns[j]  # getting the name of column\n",
    "                col_corr.add(colname)\n",
    "    af_corr = dataset.drop(col_corr,axis=1)\n",
    "    return af_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38e5def8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1272, 72)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "af_both2 = correlation(df2, .8)\n",
    "af_both2.shape\n",
    "af_both3 = correlation2(af_both2, .8)\n",
    "af_both3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0533ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['min_EffectiveCoordination', 'max_EffectiveCoordination',\n",
       "       'min_MeanBondLength', 'var_BondLengthVariation',\n",
       "       'min_BondLengthVariation', 'max_BondLengthVariation', 'var_CellVolume',\n",
       "       'mean_WCMagnitude_Shell3', 'MaxPackingEfficiency',\n",
       "       'min_NeighDiff_shell1_AtomicWeight', 'range_NeighDiff_shell1_Row',\n",
       "       'range_NeighDiff_shell1_Electronegativity',\n",
       "       'range_NeighDiff_shell1_NpValence', 'range_NeighDiff_shell1_NdValence',\n",
       "       'range_NeighDiff_shell1_NValance', 'min_NeighDiff_shell1_NpUnfilled',\n",
       "       'range_NeighDiff_shell1_NpUnfilled', 'min_NeighDiff_shell1_GSvolume_pa',\n",
       "       'range_NeighDiff_shell1_GSvolume_pa',\n",
       "       'range_NeighDiff_shell1_GSbandgap',\n",
       "       'range_NeighDiff_shell1_SpaceGroupNumber', 'NComp', 'Comp_L10Norm',\n",
       "       'max_MeltingT', 'most_MeltingT', 'mean_Column', 'dev_Column', 'dev_Row',\n",
       "       'max_Row', 'dev_CovalentRadius', 'min_CovalentRadius', 'max_NpValence',\n",
       "       'dev_NdValence', 'most_NfValence', 'min_NValance', 'most_NValance',\n",
       "       'max_NsUnfilled', 'min_NsUnfilled', 'most_NsUnfilled', 'dev_NpUnfilled',\n",
       "       'max_NpUnfilled', 'min_NpUnfilled', 'most_NdUnfilled', 'max_NUnfilled',\n",
       "       'min_NUnfilled', 'most_NUnfilled', 'max_GSvolume_pa', 'min_GSvolume_pa',\n",
       "       'most_GSvolume_pa', 'max_GSbandgap', 'min_GSbandgap', 'most_GSbandgap',\n",
       "       'max_GSmagmom', 'most_GSmagmom', 'max_SpaceGroupNumber',\n",
       "       'min_SpaceGroupNumber', 'most_SpaceGroupNumber', 'frac_sValence',\n",
       "       'frac_pValence', 'frac_dValence', 'frac_fValence', 'CanFormIonic',\n",
       "       'MeanIonicChar'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "af_both3.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24212d56",
   "metadata": {},
   "source": [
    "Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f09d5827",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MinMax Scaling\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(af_both3)\n",
    "df_scaled = scaler.transform(af_both3)\n",
    "df_scaled_d = pd.DataFrame(df_scaled)\n",
    "df_scaled_d.columns = af_both3.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748c15fc",
   "metadata": {},
   "source": [
    "# Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f85a45bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training and testing 80%-20% split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_scaled_d, Y,test_size=0.2,random_state =123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ef21b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:35<00:00,  1.19it/s]\n"
     ]
    }
   ],
   "source": [
    "#Analysis of promising algorithms using LazyPredict\n",
    "reg = LazyRegressor(verbose=0,ignore_warnings=False, custom_metric=None)\n",
    "models,predictions = reg.fit(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc664508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9710943398560626"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using XT as the promising model to work with\n",
    "reg = ExtraTreesRegressor(n_estimators=100, random_state=0).fit(X_train, y_train)\n",
    "reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817b48b4",
   "metadata": {},
   "source": [
    "10-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "addb35a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10-fold Cross validation \n",
    "scores_r2 = []\n",
    "scores_mae = []\n",
    "scores_rmse = []\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=None, shuffle=False)\n",
    "for i, (train_index, test_index) in enumerate(kf.split(df_scaled_d)):\n",
    "    X_train,y_train  = df_scaled_d.loc[train_index],Y.loc[train_index]\n",
    "    X_test,y_test = df_scaled_d.loc[test_index],Y.loc[test_index]\n",
    "    reg = ExtraTreesRegressor(n_estimators=100, random_state=0).fit(X_train, y_train)\n",
    "    scores_r2.append(reg.score(X_test, y_test))\n",
    "    scores_mae.append(mean_absolute_error(reg.predict(X_test),y_test))\n",
    "    scores_rmse.append(math.sqrt(mean_squared_error(reg.predict(X_test),y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e553a6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-13.105163608204412 3.49873589664287 4.311884268187535\n"
     ]
    }
   ],
   "source": [
    "#Estimating R^2, MAE, RMSE of the model\n",
    "r2_sum = sum(scores_r2)/10\n",
    "mae_sum = sum(scores_mae)/10\n",
    "rmse_sum = sum(scores_rmse)/10\n",
    "print(r2_sum, mae_sum, rmse_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0699b0",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d30258af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation of the model using more validation data\n",
    "val= pd.read_csv() #Please add any validation data\n",
    "val_reduced = val[X_train.columns]\n",
    "val_scaled = scaler.transform(val_reduced)\n",
    "val_scaled_d = pd.DataFrame(val_scaled)\n",
    "val_scaled_d.columns = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64a8e1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building the dinal mnodel\n",
    "reg = ExtraTreesRegressor(n_estimators=100, random_state=96)\n",
    "reg.fit(df_scaled_d,Y)\n",
    "outcome = reg.predict(val_scaled_d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
